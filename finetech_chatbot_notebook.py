# -*- coding: utf-8 -*-
"""IRWA_CHATBOT2.30.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zY0pZzBQARKl9qu4aFGBNWjxBonHhCE0

# Chatbot for E-commerce Platform with Rule-Based Responses
This notebook contains the code to train and run a chatbot for an e-commerce platform.
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
nltk.download('punkt')
nltk.download('stopwords')

from nltk.stem import WordNetLemmatizer, PorterStemmer
from nltk.corpus import wordnet
from sklearn.metrics import classification_report, accuracy_score

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')



product_df = pd.read_csv('dataset/product_data.csv')
conversational_df = pd.read_csv('dataset/conversational_data.csv')

lemmatizer = WordNetLemmatizer()
stemmer = PorterStemmer()

# Function to get synonyms of a word using WordNet
def get_synonyms(word):
    synonyms = set()
    for syn in wordnet.synsets(word):
        for lemma in syn.lemmas():
            synonyms.add(lemma.name())
    return list(synonyms)

def preprocess_text(text):
    # 1. Case Insensitivity
    text = text.lower()

    # 2. Tokenization
    tokens = word_tokenize(text)

    # 3. Stopword Removal
    tokens = [t for t in tokens if t not in stopwords.words('english')]

    # 4. Stemming
    tokens = [stemmer.stem(t) for t in tokens]

    # 5. Lemmatization
    tokens = [lemmatizer.lemmatize(t) for t in tokens]

    # 6. Handling Similar Words using WordNet
    tokens_synonyms = []
    for token in tokens:
        synonyms = get_synonyms(token)
        if synonyms:
            tokens_synonyms.extend(synonyms)
        else:
            tokens_synonyms.append(token)

    return ' '.join(tokens_synonyms)

product_df.head()

conversational_df['ProcessedQuery'] = conversational_df['UserQuery'].apply(preprocess_text)

# Splitting the data
X_train, X_test, y_train, y_test = train_test_split(conversational_df['ProcessedQuery'], conversational_df['Intent'], test_size=0.2)

# Building the intent classifier
intent_classifier = make_pipeline(TfidfVectorizer(), StandardScaler(with_mean=False), SVC(kernel='linear'))
intent_classifier.fit(X_train, y_train)

def extract_product_name(query):
    for product in product_df['ProductName']:
        if product.lower() in query.lower():
            return product
    return None

def generate_response(user_query):
    # 1. Directly match user queries to known questions (case-insensitive) for rows starting from 302
    matched_responses = conversational_df.iloc[301:].loc[conversational_df['UserQuery'].str.lower() == user_query.lower(), 'Intent'].values
    if matched_responses.size > 0:
        return matched_responses[0]

    # 2. Preprocess the user query
    preprocessed_user_query = preprocess_text(user_query)
    
    # 3. Predict the intent using the intent_classifier (It already contains the vectorizer)
    intent = intent_classifier.predict([preprocessed_user_query])[0]
    
    # 4. Extract product name if any
    product_name = extract_product_name(user_query)

    # 5. Generate a response based on the intent and product name
    if intent == "PriceInquiry" and product_name:
        price = product_df[product_df['ProductName'] == product_name]['Price_LKR'].values[0]
        return f"The price of the {product_name} is LKR {price}."
    elif intent == "ProductDetails" and product_name:
        description = product_df[product_df['ProductName'] == product_name]['Description'].values[0]
        return f"The {product_name} has the following features: {description}."
    elif intent == "ProductAvailability" and product_name:
        return f"Yes, we have the {product_name} in stock."
    else:
        return "I'm sorry, I couldn't understand that. Can you please rephrase or ask something else?"

user_query = "How much is apple iPad air?"
print(generate_response(user_query))

import joblib

# Save the model to disk
joblib.dump(intent_classifier, 'intent_classifier.pkl')

# Predict intents on the test data
y_pred = intent_classifier.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
